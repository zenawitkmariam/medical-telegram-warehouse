{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Text Chunking, Embedding & Vector Store Indexing\n",
    "\n",
    "This notebook demonstrates the vector store indexing pipeline:\n",
    "1. Load preprocessed complaints\n",
    "2. Chunk text using RecursiveCharacterTextSplitter\n",
    "3. Generate embeddings with sentence-transformers\n",
    "4. Build and persist FAISS index\n",
    "\n",
    "**Note:** For full indexing of 471k complaints, use `python src/index_vector_store.py` instead (takes ~23 min)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/Documents/Intelligent-Complaint-Analysis-for-Financial-Services/.venv/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import faiss\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "FILTERED_DATA_PATH = Path('../data/filtered_complaints.csv')\n",
    "VECTOR_STORE_PATH = Path('../vector_store')\n",
    "FAISS_INDEX_PATH = VECTOR_STORE_PATH / 'faiss_index.bin'\n",
    "METADATA_PATH = VECTOR_STORE_PATH / 'metadata.pkl'\n",
    "\n",
    "# Chunking parameters\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 100\n",
    "\n",
    "# Embedding model\n",
    "EMBEDDING_MODEL = 'sentence-transformers/paraphrase-MiniLM-L3-v2'\n",
    "EMBEDDING_DIM = 384\n",
    "\n",
    "# For demo, limit rows (set to None for full dataset)\n",
    "DEMO_LIMIT = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total complaints: 471,668\n",
      "Using demo subset: 1,000 complaints\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>product</th>\n",
       "      <th>product_original</th>\n",
       "      <th>sub_product</th>\n",
       "      <th>issue</th>\n",
       "      <th>sub_issue</th>\n",
       "      <th>narrative</th>\n",
       "      <th>company</th>\n",
       "      <th>date_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14069121</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>Store credit card</td>\n",
       "      <td>Getting a credit card</td>\n",
       "      <td>Card opened without my consent or knowledge</td>\n",
       "      <td>a [REDACTED] [REDACTED] card was opened under ...</td>\n",
       "      <td>CITIBANK, N.A.</td>\n",
       "      <td>2025-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14061897</td>\n",
       "      <td>savings_account</td>\n",
       "      <td>Checking or savings account</td>\n",
       "      <td>Checking account</td>\n",
       "      <td>Managing an account</td>\n",
       "      <td>Deposits and withdrawals</td>\n",
       "      <td>i made the mistake of using my wellsfargo debi...</td>\n",
       "      <td>WELLS FARGO &amp; COMPANY</td>\n",
       "      <td>2025-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14047085</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>General-purpose credit card or charge card</td>\n",
       "      <td>Other features, terms, or problems</td>\n",
       "      <td>Other problem</td>\n",
       "      <td>dear cfpb, i have a secured credit card with c...</td>\n",
       "      <td>CITIBANK, N.A.</td>\n",
       "      <td>2025-06-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14040217</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>General-purpose credit card or charge card</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Account information incorrect</td>\n",
       "      <td>i have a citi rewards cards. the credit balanc...</td>\n",
       "      <td>CITIBANK, N.A.</td>\n",
       "      <td>2025-06-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13968411</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>General-purpose credit card or charge card</td>\n",
       "      <td>Problem with a purchase shown on your statement</td>\n",
       "      <td>Credit card company isn't resolving a dispute ...</td>\n",
       "      <td>b'i am writing to dispute the following charge...</td>\n",
       "      <td>CITIBANK, N.A.</td>\n",
       "      <td>2025-06-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   complaint_id          product             product_original  \\\n",
       "0      14069121      credit_card                  Credit card   \n",
       "1      14061897  savings_account  Checking or savings account   \n",
       "2      14047085      credit_card                  Credit card   \n",
       "3      14040217      credit_card                  Credit card   \n",
       "4      13968411      credit_card                  Credit card   \n",
       "\n",
       "                                  sub_product  \\\n",
       "0                           Store credit card   \n",
       "1                            Checking account   \n",
       "2  General-purpose credit card or charge card   \n",
       "3  General-purpose credit card or charge card   \n",
       "4  General-purpose credit card or charge card   \n",
       "\n",
       "                                             issue  \\\n",
       "0                            Getting a credit card   \n",
       "1                              Managing an account   \n",
       "2               Other features, terms, or problems   \n",
       "3             Incorrect information on your report   \n",
       "4  Problem with a purchase shown on your statement   \n",
       "\n",
       "                                           sub_issue  \\\n",
       "0        Card opened without my consent or knowledge   \n",
       "1                           Deposits and withdrawals   \n",
       "2                                      Other problem   \n",
       "3                      Account information incorrect   \n",
       "4  Credit card company isn't resolving a dispute ...   \n",
       "\n",
       "                                           narrative                company  \\\n",
       "0  a [REDACTED] [REDACTED] card was opened under ...         CITIBANK, N.A.   \n",
       "1  i made the mistake of using my wellsfargo debi...  WELLS FARGO & COMPANY   \n",
       "2  dear cfpb, i have a secured credit card with c...         CITIBANK, N.A.   \n",
       "3  i have a citi rewards cards. the credit balanc...         CITIBANK, N.A.   \n",
       "4  b'i am writing to dispute the following charge...         CITIBANK, N.A.   \n",
       "\n",
       "  date_received  \n",
       "0    2025-06-13  \n",
       "1    2025-06-13  \n",
       "2    2025-06-12  \n",
       "3    2025-06-12  \n",
       "4    2025-06-09  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(FILTERED_DATA_PATH)\n",
    "print(f\"Total complaints: {len(df):,}\")\n",
    "\n",
    "if DEMO_LIMIT:\n",
    "    df = df.head(DEMO_LIMIT)\n",
    "    print(f\"Using demo subset: {len(df):,} complaints\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Chunking\n",
    "\n",
    "We use `RecursiveCharacterTextSplitter` from LangChain:\n",
    "- **chunk_size=500**: Keeps chunks focused while preserving context\n",
    "- **chunk_overlap=100**: Ensures continuity between chunks\n",
    "- **separators**: Prioritizes splitting at paragraph/sentence boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original length: 541 chars\n",
      "Number of chunks: 2\n",
      "\n",
      "First chunk (332 chars):\n",
      "a [REDACTED] [REDACTED] card was opened under my name by a fraudster. i received a notice from [REDACTED] that an account was just opened under my name. i reached out to [REDACTED] [REDACTED] to state that this activity was unauthorized and not me. [REDACTED] [REDACTED] confirmed this was fraudulent...\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Example: chunk a single narrative\n",
    "sample_narrative = df['narrative'].iloc[0]\n",
    "sample_chunks = splitter.split_text(sample_narrative)\n",
    "\n",
    "print(f\"Original length: {len(sample_narrative)} chars\")\n",
    "print(f\"Number of chunks: {len(sample_chunks)}\")\n",
    "print(f\"\\nFirst chunk ({len(sample_chunks[0])} chars):\")\n",
    "print(sample_chunks[0][:300] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f630a4a7d5c445f28d141b8d4b4f10d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunking:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 3,673 chunks from 1,000 complaints\n",
      "Average chunks per complaint: 3.67\n"
     ]
    }
   ],
   "source": [
    "# Chunk all complaints\n",
    "chunks = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Chunking\"):\n",
    "    narrative = row['narrative']\n",
    "    if pd.isna(narrative) or not narrative.strip():\n",
    "        continue\n",
    "    \n",
    "    text_chunks = splitter.split_text(narrative)\n",
    "    \n",
    "    for i, chunk_text in enumerate(text_chunks):\n",
    "        chunk_id = hashlib.md5(f\"{row['complaint_id']}_{i}\".encode()).hexdigest()\n",
    "        \n",
    "        chunks.append({\n",
    "            'id': chunk_id,\n",
    "            'text': chunk_text,\n",
    "            'metadata': {\n",
    "                'complaint_id': str(row['complaint_id']),\n",
    "                'product': row['product'],\n",
    "                'product_original': row['product_original'] if pd.notna(row['product_original']) else '',\n",
    "                'issue': row['issue'] if pd.notna(row['issue']) else '',\n",
    "                'company': row['company'] if pd.notna(row['company']) else '',\n",
    "                'chunk_index': i,\n",
    "                'total_chunks': len(text_chunks)\n",
    "            }\n",
    "        })\n",
    "\n",
    "print(f\"\\nCreated {len(chunks):,} chunks from {len(df):,} complaints\")\n",
    "print(f\"Average chunks per complaint: {len(chunks)/len(df):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: sentence-transformers/paraphrase-MiniLM-L3-v2\n",
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model\n",
    "model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "print(f\"Model: {EMBEDDING_MODEL}\")\n",
    "print(f\"Embedding dimension: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0b0651ce6746a48f4726c80b625657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embeddings shape: (3673, 384)\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings\n",
    "texts = [c['text'] for c in chunks]\n",
    "embeddings = model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "print(f\"\\nEmbeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built with 3,673 vectors\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS index (L2 distance)\n",
    "index = faiss.IndexFlatL2(EMBEDDING_DIM)\n",
    "\n",
    "# Add embeddings\n",
    "embeddings_float32 = embeddings.astype('float32')\n",
    "index.add(embeddings_float32)\n",
    "\n",
    "print(f\"FAISS index built with {index.ntotal:,} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata entries: 3,673\n"
     ]
    }
   ],
   "source": [
    "# Prepare metadata for storage\n",
    "metadata_list = []\n",
    "for c in chunks:\n",
    "    metadata_list.append({\n",
    "        'id': c['id'],\n",
    "        'text': c['text'],\n",
    "        **c['metadata']\n",
    "    })\n",
    "\n",
    "print(f\"Metadata entries: {len(metadata_list):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'billing dispute credit card'\n",
      "\n",
      "Top 5 results:\n",
      "\n",
      "1. [Distance: 25.5237] Product: credit_card\n",
      "   Issue: Problem with a purchase shown on your statement\n",
      "   Text: . the credit card company is acting in fraudulent matter making me pay a charge for something i no longer have,...\n",
      "\n",
      "2. [Distance: 26.3177] Product: credit_card\n",
      "   Issue: Fees or interest\n",
      "   Text: am writing to formally address serious concerns regarding my experience with the credit card account issued by your company, under account number [RED...\n",
      "\n",
      "3. [Distance: 26.3630] Product: credit_card\n",
      "   Issue: Getting a credit card\n",
      "   Text: . i believe this constitutes a violation of the fair credit billing act and request immediate assistance in resolving this matter....\n",
      "\n",
      "4. [Distance: 26.7926] Product: credit_card\n",
      "   Issue: Problem with a purchase shown on your statement\n",
      "   Text: . at this point, they were already hand my credit card and had the information. no charge was put on my card until i arrived back in the us where they...\n",
      "\n",
      "5. [Distance: 26.8287] Product: credit_card\n",
      "   Issue: Getting a credit card\n",
      "   Text: . they used the card, overdrawn it, and now that debt appears on my credit score. i filed a complaint with [REDACTED], and i started a fraud dispute w...\n"
     ]
    }
   ],
   "source": [
    "# Test semantic search\n",
    "test_query = \"billing dispute credit card\"\n",
    "query_embedding = model.encode([test_query], convert_to_numpy=True).astype('float32')\n",
    "\n",
    "k = 5\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "print(f\"Query: '{test_query}'\")\n",
    "print(f\"\\nTop {k} results:\")\n",
    "for i, (dist, idx) in enumerate(zip(distances[0], indices[0]), 1):\n",
    "    meta = metadata_list[idx]\n",
    "    print(f\"\\n{i}. [Distance: {dist:.4f}] Product: {meta['product']}\")\n",
    "    print(f\"   Issue: {meta['issue']}\")\n",
    "    print(f\"   Text: {meta['text'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Index (Optional)\n",
    "\n",
    "**Note:** This demo uses a subset. For full indexing, run:\n",
    "```bash\n",
    "python src/index_vector_store.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save demo index\n",
    "# VECTOR_STORE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "# faiss.write_index(index, str(FAISS_INDEX_PATH))\n",
    "# with open(METADATA_PATH, 'wb') as f:\n",
    "#     pickle.dump(metadata_list, f)\n",
    "# print(\"Index saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Step | Output |\n",
    "|------|--------|\n",
    "| Chunking | 500 chars, 100 overlap |\n",
    "| Embedding | paraphrase-MiniLM-L3-v2 (384-dim) |\n",
    "| Index | FAISS IndexFlatL2 |\n",
    "\n",
    "For full production indexing (~23 min for 471k complaints â†’ 1.6M chunks), use the CLI script."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
